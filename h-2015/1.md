---
layout: statistics-past-test-question
prob_tags: 회귀분석 회귀계수 최소제곱추정법
math: true
---
1)

<div>
#### 회귀계수 추정량 도출 ####

최소제곱추정법에 의해 오차제곱합 $ S $

$$ S = \sum_ {i=1}^n e_ i^2 = \sum_ {i=1}^n \left( Y_ i - b_0 \right) ^2 $$

를 극소화하는 $ b_0 $ 를 구하면

$$ \begin{eqnarray}
\frac{\partial S}{\partial b_0} &=& -2 \sum_ {i=1}^n \left( Y_ i - b_0 \right) = -2 n \left( \bar Y - b_0 \right) = 0 \\
\end{eqnarray} $$

이를 정리하면

$$ b_0 = \bar Y $$

#### 최소제곱추정량의 기댓값 ####

$$ \begin{eqnarray} E[b_0] &=& E[\bar Y] = E[ \frac{1}{n} \sum_ {i=1}^n Y_i ] = \frac{1}{n} \sum_ {i=1}^n E[Y_i]\\
&=& \frac{1}{n} \sum_ {i=1}^n E[\beta_0 + \epsilon_i] = \frac{1}{n} \sum_ {i=1}^n \beta_0  + \frac{1}{n} \sum_ {i=1}^n \underbrace{E[\epsilon_i]}_{=0}  \\
&=& \beta_0
\end{eqnarray} $$

따라서 $ b_0 $ 는 불편추정량이다.

#### 최소제곱추정량의 분산 ####

$$ \begin{eqnarray} V[b_0] &=& V[\bar Y] = V[ \frac{1}{n} \sum_ {i=1}^n Y_i ]\\
&=& \frac{1}{n^2} \sum_ {i=1}^n V[Y_i] + 2 \sum_{i<j} \underbrace {Cov[Y_i, Y_j]}_{=0} \\
&=& \frac{1}{n^2} \sum_ {i=1}^n V[\beta_0 + \epsilon_i] = \frac{1}{n^2} \sum_ {i=1}^n V[\epsilon_i] = \frac{1}{n^2} \sum_ {i=1}^n \sigma^2 \\
&=& \frac{\sigma^2}{n}
\end{eqnarray} $$

</div>

2)

<div>
#### 회귀계수 추정량 도출 ####

최소제곱추정법에 의해 오차제곱합 $ S $

$$ S = \sum_ {i=1}^n e_ i^2 = \sum_ {i=1}^n \left( Y_ i - b_1 x_i \right) ^2 $$

를 극소화하는 $ b_1 $ 를 구하면

$$ \begin{eqnarray}
\frac{\partial S}{\partial b_1} &=& -2 \sum_ {i=1}^n x_i \left( Y_ i - b_1 x_i \right) =

- 2 \left( \sum_ {i=1}^n x_ i Y_i - b_1 \sum_ {i=1}^n x_ i ^2 \right) = 0
\end{eqnarray} $$

이를 정리하면

$$ b_1 = \frac{1}{\sum_ {i=1}^n x_ i ^2 } \sum_ {i=1}^n x_ i Y_i $$

#### 최소제곱추정량의 기댓값 ####

$$ \begin{eqnarray} E[b_1] &=& E \left[\frac{1}{\sum_ {i=1}^n x_ i ^2 } \sum_ {i=1}^n x_ i Y_i \right ]
= \frac{1}{\sum_ {i=1}^n x_ i ^2 } \sum_ {i=1}^n x_ i E [ Y_i ] \\
&=& \frac{1}{\sum_ {i=1}^n x_ i ^2 } \sum_ {i=1}^n x_ i E [ \beta_1 x_i + \epsilon_i ] \\
&=& \frac{\beta_1}{\sum_ {i=1}^n x_ i ^2 } \sum_ {i=1}^n x_ i^2 + \frac{1}{\sum_ {i=1}^n x_ i ^2 } \sum_ {i=1}^n x_i \underbrace {E[\epsilon_i]}_{=0} \\
&=& \beta_1
\end{eqnarray} $$

따라서 $ b_1 $ 는 불편추정량이다.

#### 최소제곱추정량의 분산 ####

$$ \begin{eqnarray} V[b_1] &=& V\left[\frac{1}{\sum_ {i=1}^n x_ i ^2 } \sum_ {i=1}^n x_ i Y_i \right ] \\
&=& \frac{1}{\left ( \sum_ {i=1}^n x_ i ^2 \right ) ^2 } \sum_ {i=1}^n x_i ^2 V[Y_i] + 2 \frac{1}{\left ( \sum_ {i=1}^n x_ i ^2 \right ) ^2 } \sum_{i<j} x_i x_j \underbrace {Cov[Y_i, Y_j]}_{=0} \\
&=& \frac{1}{\left ( \sum_ {i=1}^n x_ i ^2 \right ) ^2 } \sum_ {i=1}^n x_i ^2 V[\beta_1 x_i + \epsilon_i]
= \frac{1}{\left ( \sum_ {i=1}^n x_ i ^2 \right ) ^2 } \sum_ {i=1}^n x_i ^2 V[\epsilon_i] \\
&=& \frac{\sigma^2}{\left ( \sum_ {i=1}^n x_ i ^2 \right ) ^2 } \sum_ {i=1}^n x_i ^2 \\
&=& \frac{\sigma^2}{ \sum_ {i=1}^n x_ i ^2} 
\end{eqnarray} $$

</div>
